{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1 : Import All Necessary Library</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.metrics.cluster import entropy\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import csv\n",
    "import math\n",
    "import scipy.spatial.distance as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2 : Define the Color Quantization Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorQuantization(colorChannelImage, bins, max_color = 255):\n",
    "    # change color variance to bins variance\n",
    "    quant = np.array(colorChannelImage) * (bins / max_color)\n",
    "    quant = np.floor(quant)\n",
    "    quant[quant>=bins] = bins - 1\n",
    "    \n",
    "    return quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineColorQuantization(image, B_bins, G_bins, R_bins):\n",
    "    # extract matrix of color channel image\n",
    "    B = image[:,:,0]\n",
    "    G = image[:,:,1]\n",
    "    R = image[:,:,2]\n",
    "    \n",
    "    # kuantisasikan tiap color channel\n",
    "    B_quant = colorQuantization(B, B_bins)\n",
    "    G_quant = colorQuantization(G, G_bins)\n",
    "    R_quant = colorQuantization(R, R_bins)\n",
    "    \n",
    "    # combine the color quantization\n",
    "    combine_quant = (B_bins * G_bins * R_quant) + (B_bins * G_quant) + B_quant\n",
    "    \n",
    "    return combine_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3 : Define the Edge Quantization Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeQuantization(image, binsTheta) :\n",
    "    # extract matrix of color channel image\n",
    "    B = image[:,:,0]\n",
    "    G = image[:,:,1]\n",
    "    R = image[:,:,2]\n",
    "\n",
    "    # sobel implementation\n",
    "    Bx = cv2.Sobel(B,cv2.CV_64F,1,0,ksize=3)\n",
    "    By = cv2.Sobel(B,cv2.CV_64F,0,1,ksize=3)\n",
    "    Gx = cv2.Sobel(G,cv2.CV_64F,1,0,ksize=3)\n",
    "    Gy = cv2.Sobel(G,cv2.CV_64F,0,1,ksize=3)\n",
    "    Rx = cv2.Sobel(R,cv2.CV_64F,1,0,ksize=3)\n",
    "    Ry = cv2.Sobel(R,cv2.CV_64F,0,1,ksize=3)\n",
    "\n",
    "    # get |a| and |b|\n",
    "    a = sqrt(Bx**2 + Gx**2 + Rx**2)\n",
    "    b = sqrt(By**2 + Gy**2 + Ry**2)\n",
    "\n",
    "    # get ab\n",
    "    ab = (Bx*By) + (Gx*Gy) + (Rx*Ry)\n",
    "\n",
    "    # image orientation\n",
    "    (h, w) = a.shape\n",
    "    #binsTheta = 18\n",
    "    theta = np.zeros((h,w))\n",
    "\n",
    "    # edge quantization\n",
    "    for i in range (0, h) :\n",
    "        for j in range (0, w) :\n",
    "            if (a[i,j] == 0 or b[i,j] == 0):\n",
    "                cosab1 = 0;\n",
    "            else :\n",
    "                cosab1 = ab[i,j]/(a[i,j]*b[i,j])\n",
    "            theta1 = math.degrees(np.arccos(cosab1))\n",
    "            if (math.isnan(theta1)):\n",
    "                theta1 = 0\n",
    "            theta[i,j] = math.floor(theta1 * (binsTheta/180))\n",
    "            if (theta[i,j] >= binsTheta-1) :\n",
    "                theta[i,j] = binsTheta-1\n",
    "    \n",
    "    return np.array(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 4 : Define the Texton Search Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textonSearch(colorQuant, cBins, edgeQuant, eBins) :\n",
    "    # define the shape of image\n",
    "    (h, w) = colorQuant.shape\n",
    "\n",
    "    color_img = np.zeros((h,w))\n",
    "    edge_img = np.zeros((h,w))\n",
    "    \n",
    "    # sliding window check for all color channel\n",
    "    for i in range (0, h, 2) :\n",
    "        for j in range (0, w, 2) :\n",
    "            \n",
    "            # texton search for color\n",
    "            cTemp = colorQuant[i:i+2,j:j+2]\n",
    "            if (cTemp[0,0] == cTemp[0,1]) :    # texton type 1\n",
    "                color_img[i,j] = colorQuant[i,j]\n",
    "                color_img[i,j+1] = colorQuant[i,j+1]\n",
    "            if (cTemp[0,0] == cTemp[1,0]) :    # texton type 2\n",
    "                color_img[i,j] = colorQuant[i,j]\n",
    "                color_img[i+1,j] = colorQuant[i+1,j]\n",
    "            if (cTemp[0,0] == cTemp[1,1]) :    # texton type 3\n",
    "                color_img[i,j] = colorQuant[i,j]\n",
    "                color_img[i+1,j+1] = colorQuant[i+1,j+1]\n",
    "            if (cTemp[1,0] == cTemp[1,1]) :    # texton type 4\n",
    "                color_img[i+1,j] = colorQuant[i+1,j]\n",
    "                color_img[i+1,j+1] = colorQuant[i+1,j+1]\n",
    "            if (cTemp[0,1] == cTemp[1,1]) :    # texton type 5\n",
    "                color_img[i,j+1] = colorQuant[i,j+1]\n",
    "                color_img[i+1,j+1] = colorQuant[i+1,j+1]\n",
    "            if (cTemp[0,1] == cTemp[1,0]) :    # texton type 6\n",
    "                color_img[i,j+1] = colorQuant[i,j+1]\n",
    "                color_img[i+1,j] = colorQuant[i+1,j]\n",
    "                \n",
    "            # texton search for edge\n",
    "            eTemp = edgeQuant[i:i+2,j:j+2]\n",
    "            if (eTemp[0,0] == eTemp[0,1]) :    # texton type 1\n",
    "                edge_img[i,j] = edgeQuant[i,j]\n",
    "                edge_img[i,j+1] = edgeQuant[i,j+1]\n",
    "            if (eTemp[0,0] == eTemp[1,0]) :    # texton type 2\n",
    "                edge_img[i,j] = edgeQuant[i,j]\n",
    "                edge_img[i+1,j] = edgeQuant[i+1,j]\n",
    "            if (eTemp[0,0] == eTemp[1,1]) :    # texton type 3\n",
    "                edge_img[i,j] = edgeQuant[i,j]\n",
    "                edge_img[i+1,j+1] = edgeQuant[i+1,j+1]\n",
    "            if (eTemp[1,0] == eTemp[1,1]) :    # texton type 4\n",
    "                edge_img[i+1,j] = edgeQuant[i+1,j]\n",
    "                edge_img[i+1,j+1] = edgeQuant[i+1,j+1]\n",
    "            if (eTemp[0,1] == eTemp[1,1]) :    # texton type 5\n",
    "                edge_img[i,j+1] = edgeQuant[i,j+1]\n",
    "                edge_img[i+1,j+1] = edgeQuant[i+1,j+1]\n",
    "            if (eTemp[0,1] == eTemp[1,0]) :    # texton type 6\n",
    "                edge_img[i,j+1] = edgeQuant[i,j+1]\n",
    "                edge_img[i+1,j] = edgeQuant[i+1,j]\n",
    "    \n",
    "    # make color histogram\n",
    "    cF = np.histogram(color_img.ravel(),cBins,[0,64])\n",
    "    colorFeatures = (np.array(cF[0]) / 6) # perlu dibagi dg 6 meyesuaikan dg jumlah type texton yg digunakan\n",
    "    \n",
    "    # make edge histogram\n",
    "    eF = np.histogram(edge_img.ravel(),eBins,[0,18])\n",
    "    edgeFeatures = (np.array(eF[0]) / 6)\n",
    "    \n",
    "    # combine color and edge features\n",
    "    features = []\n",
    "    features.extend(colorFeatures)\n",
    "    features.extend(edgeFeatures)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 5 : Define the GLCM Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCM(image) :\n",
    "    # convert iamge to greyscale\n",
    "    grey_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # make co-occurance matrix\n",
    "    gm = greycomatrix(grey_img, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256, normed=True)\n",
    "    (h,w) = gm[:,:,0,0].shape\n",
    "    \n",
    "    glcm_features = []\n",
    "    \n",
    "    # calculate energy, contrast, correlation, entropy\n",
    "    # using scikit library\n",
    "    energy = greycoprops(gm, 'energy')\n",
    "    contrast = greycoprops(gm, 'contrast')\n",
    "    correlation = greycoprops(gm, 'correlation')\n",
    "    glcm_features.extend(energy.tolist())\n",
    "    glcm_features.extend(contrast.tolist())\n",
    "    glcm_features.extend(correlation.tolist())\n",
    "    \n",
    "    entropy = []\n",
    "    for i in range (0, 4):\n",
    "        e = np.abs(gm[:,:,0,i]*np.log2(gm[:,:,0,i]))\n",
    "        e[isnan(e)] = 0\n",
    "        entropy.append(sum(e))\n",
    "        \n",
    "    # using manual calculation\n",
    "    \"\"\"\n",
    "    energy = []\n",
    "    contrast = []\n",
    "    correlation = []\n",
    "    entropy = []\n",
    "    # buat matriks perkalian antara baris & koom utk menghitung contrast\n",
    "    mcross = np.zeros((h,w))\n",
    "    mcross2 = np.zeros((h,w))\n",
    "    mcross3 = np.zeros((h,w))\n",
    "    for i in range (1, h+1):\n",
    "        for j in range (1, w+1):\n",
    "            mcross[i-1,j-1] = (i-j)**2\n",
    "            mcross2[i-1,j-1] = (0-j)**2\n",
    "            mcross3[i-1,j-1] = i*j\n",
    "    # hitung energy, contrast, correalation, entropy\n",
    "    for i in range (0, 4):\n",
    "        energy.append(sum(gm[:,:,0,i]**2))\n",
    "        if (i == 0):\n",
    "            contrast.append(sum(mcross*gm[:,:,0,i]))\n",
    "        else:\n",
    "            contrast.append(sum(mcross2*gm[:,:,0,i]))\n",
    "        correlation.append(sum(mcross3*gm[:,:,0,i]))\n",
    "        e = np.abs(gm[:,:,0,i]*np.log2(gm[:,:,0,i]))\n",
    "        e[isnan(e)] = 0\n",
    "        entropy.append(sum(e))\n",
    "    glcm_features.extend(energy)\n",
    "    glcm_features.extend(contrast)\n",
    "    glcm_features.extend(correlation)\n",
    "    #glcm_features.extend(entropy)\n",
    "    \"\"\"\n",
    "    return glcm_features, entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 6 : Define the Searcher Class</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Searcher:\n",
    "    def __init__(self, train):\n",
    "        # store the index path\n",
    "        self.train = train\n",
    "        \n",
    "    def search(self, queryFeatures, limit=5):\n",
    "        # initialize our dictionary of results\n",
    "        results = {}\n",
    "    \n",
    "        # loop over the rows in the index\n",
    "        for row in train:\n",
    "            features = [float(x) for x in row[1:]]\n",
    "                \n",
    "            d = self.canberra_distance(features, queryFeatures)\n",
    "            results[row[0]] = d\n",
    "                \n",
    "        results = sorted([(v,k) for (k,v) in results.items()])\n",
    "        \n",
    "        # return our (limited) results\n",
    "        return results[:limit]\n",
    "    \n",
    "    def canberra_distance(self, histA, histB):\n",
    "        #d = dist.canberra(histA, histB)\n",
    "        \n",
    "        # modified canberra\n",
    "        M = len(histA)\n",
    "        mA = mean(histA)\n",
    "        mB = mean(histB)\n",
    "        d = 0\n",
    "        for i in range (0, M) :\n",
    "            d = d + ( abs(histA[i] - histB[i]) / ((abs(histA[i] + mA) + abs(histB[i] + mB))))\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 7 : The Indexing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in arccos\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\feature\\texture.py:109: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(image.dtype, np.float):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log2\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish indexing. Alhamdulillah...\n"
     ]
    }
   ],
   "source": [
    "# Describe path of data train and index file\n",
    "datatrain_path = \"dataset\"\n",
    "indexfile_path = \"indexing/TextonIndex.csv\"\n",
    "\n",
    "# define the bins for quantization\n",
    "colorBins = 64\n",
    "R_Bins = 4\n",
    "G_Bins = 4\n",
    "B_Bins = 4\n",
    "edgeBins = 18\n",
    "\n",
    "# open the output index file for writing\n",
    "output = open(indexfile_path, 'w')\n",
    "\n",
    "# use glob to grab the image paths and logo over them\n",
    "for imagePath in glob.glob(datatrain_path+'/*.jpg'):\n",
    "    # extract the image ID (i.e. the unique filename) from the image path and load the image itself\n",
    "    imageID = imagePath[imagePath.rfind('/') + 1:]\n",
    "    image = cv2.imread(imagePath)\n",
    "    \n",
    "    # Color Quantization\n",
    "    colorQuant = combineColorQuantization(image, B_Bins, G_Bins, R_Bins)\n",
    "\n",
    "    # Edge Quantization\n",
    "    edgeQuant = edgeQuantization(image, edgeBins)\n",
    "    \n",
    "    # Texton Search\n",
    "    #features = []\n",
    "    features = textonSearch(colorQuant, colorBins, edgeQuant, edgeBins)\n",
    "    \n",
    "    # GLCM\n",
    "    glcm, en = GLCM(image)\n",
    "    \n",
    "    # write the features to file\n",
    "    #features.extend(glcm)\n",
    "    features.extend(glcm[0])\n",
    "    features.extend(glcm[1])\n",
    "    features.extend(glcm[2])\n",
    "    features.extend(en)\n",
    "    features = [str(f) for f in features]\n",
    "    output.write('%s,%s\\n' % (imageID, ','.join(features)))\n",
    "\n",
    "print('Finish indexing. Alhamdulillah...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 8 : Evaluate Model Using Cross Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5515789473684211, 0.5515789473684211, 0.5515789473684211, None)\n"
     ]
    }
   ],
   "source": [
    "# Define path of testing data and indexing file\n",
    "index_file = 'indexing/textonIndex.csv'\n",
    "\n",
    "# define the bins for quantization\n",
    "colorBins = 64\n",
    "R_Bins = 4\n",
    "G_Bins = 4\n",
    "B_Bins = 4\n",
    "edgeBins = 18\n",
    "\n",
    "y_true = []\n",
    "y_pred = []    \n",
    "\n",
    "for i in range (1, 7) :\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    with open(index_file) as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        # loop over the rows in the index\n",
    "        for row in reader:\n",
    "            if (int(row[0].split('_')[1].split('.')[0]) == i):\n",
    "                test.append(row)\n",
    "            else :\n",
    "                train.append(row)\n",
    "       \n",
    "        # close the reader\n",
    "        f.close()\n",
    "        \n",
    "    for query in test :\n",
    "        for i in range (0, 5):\n",
    "            y_true.append(query[0].split('\\\\')[1].split('_')[0])\n",
    "            \n",
    "        searcher = Searcher(train)\n",
    "        q = [float(i) for i in query[1:]]\n",
    "        results = searcher.search(q)\n",
    "            \n",
    "        for (score, resultID) in results:\n",
    "            # load the result image and store it to y_pred\n",
    "            #image = imread(resultID)\n",
    "            y_pred.append(resultID.split('\\\\')[1].split('_')[0])\n",
    "    \n",
    "# calculate the precision, recall, fscore\n",
    "evaluate = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print (evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Trial and Error</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3333333333333333, 0.3333333333333333, 0.25, 0.3333333333333333]\n",
      "[1.0, 9.666666666666666, 7.5, 4.666666666666667]\n",
      "[6.666666666666667, 6.666666666666667, 7.5, 6.666666666666667]\n",
      "[1.584962500721156, 1.584962500721156, 2.0, 1.584962500721156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\feature\\texture.py:109: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(image.dtype, np.float):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log2\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "#image = cv2.imread('dataset/B1_1.jpg')\n",
    "#grey_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "grey_img =[[0,1,2,3],[0,1,2,3],[0,1,2,3],[0,1,2,3]]\n",
    "gm = greycomatrix(grey_img, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=4, normed=True)\n",
    "# buat matriks perkalian antara baris & koom utk menghitung contrast\n",
    "h = 4\n",
    "w = 4\n",
    "mcross = np.zeros((h,w))\n",
    "mcross2 = np.zeros((h,w))\n",
    "mcross3 = np.zeros((h,w))\n",
    "for i in range (1, h+1):\n",
    "    for j in range (1, w+1):\n",
    "        mcross[i-1,j-1] = (i-j)**2\n",
    "        mcross2[i-1,j-1] = (0-j)**2\n",
    "        mcross3[i-1,j-1] = i*j\n",
    "# hitung energy, contrast, correalation, entropy\n",
    "energy = []\n",
    "contrast = []\n",
    "correlation = []\n",
    "entropy = []\n",
    "for i in range (0, 4):\n",
    "    energy.append(sum(gm[:,:,0,i]**2))\n",
    "    if (i == 0):\n",
    "        contrast.append(sum(mcross*gm[:,:,0,i]))\n",
    "    else:\n",
    "        contrast.append(sum(mcross2*gm[:,:,0,i]))\n",
    "    correlation.append(sum(mcross3*gm[:,:,0,i]))\n",
    "    e = np.abs(gm[:,:,0,i]*np.log2(gm[:,:,0,i]))\n",
    "    e[isnan(e)] = 0\n",
    "    entropy.append(sum(e))\n",
    "print (energy)\n",
    "print (contrast)\n",
    "print (correlation)\n",
    "print (entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
